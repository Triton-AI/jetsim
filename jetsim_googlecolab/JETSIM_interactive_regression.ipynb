{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7.0 64-bit ('machineLearning': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"JETSIM_interactive_regression.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","interpreter":{"hash":"bbe61bdda6d06731c87dfd44a415dcef0f84fffa03acd8316c38a76a84e11011"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aItI4pLHbKak"},"source":["Jetsim : Build Model\n","===\n","\n","### **Step 4.2** from README.md\n","\n","---\n","\n","INITIAL SETUP\n","\n","Right click and open 'this' notebook **JESTIM_interactive_regression.ipynb** in Google colab.\n","\n","Open 'Edit/Notebook settings' toolbar in Google Colab and select **GPU**\n","\n","If you get any runtime errors at anytime, go to 'Runtime' toolbar and click 'Restart Runtime'. Rerun all cells.\n","\n","For this notebook, do not click a widget or button unless it explicitly says to do so\n","---\n"]},{"cell_type":"code","metadata":{"id":"srQXifcZbMN6"},"source":["#initialize google colab\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","print(\"DONE\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vefE6hHPT3WH"},"source":["Select 'jetsim_googlecolab' directory \n","==="]},{"cell_type":"code","metadata":{"id":"IV55ouL_bSgQ"},"source":["%cd gdrive/MyDrive/jetsim_googlecolab/"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'gdrive/MyDrive/jetsim_googlecolab/'\n/Users/Parth/Desktop/jetsim/jetsim/jetsim_googlecolab\n"]}]},{"cell_type":"markdown","metadata":{"id":"PXwBsqODbKan"},"source":["Task - initialize data set\n","===\n","\n","### Place all name-converted images into 'SIM_road_following_A/m2_images' folder before running this cell."]},{"cell_type":"code","metadata":{"id":"BBIXWM8ZbKao"},"source":["import torchvision.transforms as transforms\n","from xy_dataset import XYDataset\n","\n","\n","TASK = 'SIM_road_following'\n","\n","#Folder Name\n","CATEGORIES = ['m2_images']\n","\n","#We will call this dataset A\n","DATASETS = ['A']\n","\n","# This will transform the images with different filters.\n","TRANSFORMS = transforms.Compose([\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","datasets = {}\n","for name in DATASETS:\n","    datasets[name] = XYDataset(TASK + '_' + name, CATEGORIES, TRANSFORMS, random_hflip=True)\n","\n","print(\"DONE\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B0Vx6c9zbKao"},"source":["### Data Collection"]},{"cell_type":"code","metadata":{"id":"vvmGCl6mbKao"},"source":["import cv2\n","import ipywidgets\n","import traitlets\n","from IPython.display import display\n","\n","# initialize active dataset\n","dataset = datasets[DATASETS[0]]\n","\n","dataset_widget = ipywidgets.Dropdown(options=DATASETS, description='dataset')\n","category_widget = ipywidgets.Dropdown(options=dataset.categories, description='category')\n","count_widget = ipywidgets.IntText(description='count')\n","\n","# manually update counts at initialization\n","count_widget.value = dataset.get_count(category_widget.value)\n","\n","# sets the active dataset\n","def set_dataset(change):\n","    global dataset\n","    dataset = datasets[change['new']]\n","    count_widget.value = dataset.get_count(category_widget.value)\n","dataset_widget.observe(set_dataset, names='value')\n","\n","# update counts when we select a new category\n","def update_counts(change):\n","    count_widget.value = dataset.get_count(change['new'])\n","category_widget.observe(update_counts, names='value')\n","\n","\n","def save_snapshot(_, content, msg):\n","    if content['event'] == 'click':\n","        data = content['eventData']\n","        x = data['offsetX']\n","        y = data['offsetY']\n","        \n","        # save to disk\n","        dataset.save_entry(category_widget.value, camera.value, x, y)\n","        \n","        # display saved snapshot\n","        snapshot = camera.value.copy()\n","        snapshot = cv2.circle(snapshot, (x, y), 8, (0, 255, 0), 3)\n","        snapshot_widget.value = bgr8_to_jpeg(snapshot)\n","        count_widget.value = dataset.get_count(category_widget.value)\n","        \n","# camera_widget.on_msg(save_snapshot)\n","\n","data_collection_widget = ipywidgets.VBox([\n","    dataset_widget,\n","    category_widget,\n","    count_widget\n","])\n","\n","# ipywidgets.HBox([camera_widget, snapshot_widget]),\n","# display(data_collection_widget)\n","\n","# Evalutate stuff, not needed for traing but need for code competion. \n","import threading\n","import time\n","from utils import preprocess\n","import torch.nn.functional as F\n","\n","state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n","\n","def live(state_widget, model, camera, prediction_widget):\n","    global dataset\n","            \n","def start_live(change):\n","  pass\n","\n","print(\"DONE\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mkkq6HRTbKap"},"source":["Setup empty model\n","==="]},{"cell_type":"code","metadata":{"id":"PKNZXGCHbKap"},"source":["import torch\n","import torchvision\n","\n","device = torch.device('cuda')\n","output_dim = 2 * len(dataset.categories)  # x, y coordinate for each category\n","\n","# ALEXNET\n","# model = torchvision.models.alexnet(pretrained=True)\n","# model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n","\n","# SQUEEZENET \n","# model = torchvision.models.squeezenet1_1(pretrained=True)\n","# model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n","# model.num_classes = len(dataset.categories)\n","\n","# RESNET 18\n","model = torchvision.models.resnet18(pretrained=True)\n","model.fc = torch.nn.Linear(512, output_dim)\n","\n","# RESNET 34\n","# model = torchvision.models.resnet34(pretrained=True)\n","# model.fc = torch.nn.Linear(512, output_dim)\n","\n","# DENSENET 121\n","# model = torchvision.models.densenet121(pretrained=True)\n","# model.classifier = torch.nn.Linear(model.num_features, output_dim)\n","\n","model = model.to(device)\n","\n","model_save_button = ipywidgets.Button(description='save model')\n","model_load_button = ipywidgets.Button(description='load model')\n","model_path_widget = ipywidgets.Text(description='model path', value='NAME.pth')\n","\n","def load_model(c):\n","    model.load_state_dict(torch.load(model_path_widget.value))\n","model_load_button.on_click(load_model)\n","    \n","def save_model(c):\n","    torch.save(model.state_dict(), model_path_widget.value)\n","model_save_button.on_click(save_model)\n","\n","model_widget = ipywidgets.VBox([\n","    model_path_widget,\n","    ipywidgets.HBox([model_load_button, model_save_button])\n","])\n","\n","\n","display(model_widget)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j7fHBKI8tjXt"},"source":["Rename model 'NAME.pth' and click SAVE. Wait 30 seconds. Then click LOAD in the widget above.\n","==="]},{"cell_type":"markdown","metadata":{"id":"3ny-BVRItjXu"},"source":["Setup training parameters\n","==="]},{"cell_type":"code","metadata":{"id":"sri2bsmYbKar"},"source":["BATCH_SIZE = 8\n","\n","optimizer = torch.optim.Adam(model.parameters())\n","#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n","\n","epochs_widget = ipywidgets.IntText(description='epochs', value=10)\n","eval_button = ipywidgets.Button(description='evaluate')\n","train_button = ipywidgets.Button(description='train')\n","loss_widget = ipywidgets.FloatText(description='loss')\n","progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n","\n","def train_eval(is_training):\n","    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget\n","    \n","    try:\n","        train_loader = torch.utils.data.DataLoader(\n","            dataset,\n","            batch_size=BATCH_SIZE,\n","            shuffle=True\n","        )\n","\n","        state_widget.value = 'stop'\n","        train_button.disabled = True\n","        eval_button.disabled = True\n","        time.sleep(1)\n","\n","        if is_training:\n","            model = model.train() #Set the model into training mode\n","        else:\n","            model = model.eval() #Set the model into evaluation mode\n","\n","        while epochs_widget.value > 0:\n","            i = 0\n","            sum_loss = 0.0\n","            error_count = 0.0\n","            for images, category_idx, xy in iter(train_loader):\n","                # send data to device\n","                images = images.to(device)\n","                xy = xy.to(device)\n","\n","                if is_training:\n","                    # zero gradients of parameters\n","                    optimizer.zero_grad()\n","\n","                # execute model to get outputs\n","                outputs = model(images)\n","\n","                # compute MSE loss over x, y coordinates for associated categories\n","                loss = 0.0\n","                for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n","                    loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n","                loss /= len(category_idx)\n","\n","                if is_training:\n","                    # run backpropogation to accumulate gradients\n","                    loss.backward()\n","\n","                    # step optimizer to adjust parameters\n","                    optimizer.step()\n","\n","                # increment progress\n","                count = len(category_idx.flatten())\n","                i += count\n","                sum_loss += float(loss)\n","                progress_widget.value = i / len(dataset)\n","                loss_widget.value = sum_loss / i\n","                \n","            if is_training:\n","                epochs_widget.value = epochs_widget.value - 1\n","            else:\n","                break\n","    except e:\n","        pass\n","    model = model.eval()\n","\n","    train_button.disabled = False\n","    eval_button.disabled = False\n","    state_widget.value = 'live'\n","    \n","train_button.on_click(lambda c: train_eval(is_training=True))\n","eval_button.on_click(lambda c: train_eval(is_training=False))\n","    \n","train_eval_widget = ipywidgets.VBox([\n","    epochs_widget,\n","    progress_widget,\n","    loss_widget,\n","    ipywidgets.HBox([train_button, eval_button])\n","])\n","\n","#display(train_eval_widget)\n","\n","print(\"DONE\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZsHXIuMbKas"},"source":["all_widget = ipywidgets.VBox([\n","    ipywidgets.HBox([data_collection_widget]), train_eval_widget,\n","    model_widget\n","])\n","\n","display(all_widget)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tXTuQs62tjXw"},"source":["Epoch and training tips\n","===\n","\n","---\n","\n","- Epochs = Choose 8-12.\n","- Click 'train' button.\n","- Watch blue progress bar, <5 minutes.\n","- Click 'save model' button when training is finished.\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fjV0Cdwdjxuh"},"source":["### Create the **models** folder to store all your models."]},{"cell_type":"code","metadata":{"id":"ixYBZlYdZe-2"},"source":["import os\n","dir = \"models\"\n","try:\n","    os.makedirs(dir, exist_ok = False)\n","    print(\"Directory '%s' created successfully\" % dir)\n","except OSError as error:\n","    print(\"Directory '%s' already exists\" % dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-fK5Stqkm6N"},"source":["### Move your 'model.pth' to **models** folder inside Google drive **manually**. "]},{"cell_type":"markdown","metadata":{"id":"4u6UOmNKZe-2"},"source":["### Close this notebook and proceed to **step 5** in README.md.\n","\n","### Follow **JETSIM_road_following.ipynb** notbook to test model. "]},{"cell_type":"code","metadata":{"id":"rMqrbN5Fjm6R"},"source":[],"execution_count":null,"outputs":[]}]}